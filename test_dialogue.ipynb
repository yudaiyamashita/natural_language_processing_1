{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "test_dialogue.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOVBH6kjHOSI"
      },
      "source": [
        "# 対話の検証\n",
        "前回のレクチャーで構築し、訓練したモデルにより対話文を生成します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjSoYYODHOSS"
      },
      "source": [
        "## 文字の読み込み\n",
        "使用する文字を読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBh0ti6xHOST",
        "outputId": "09a195af-6f4b-4efd-8497-85abbb3df783"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('kana_chars.pickle', mode='rb') as f:\n",
        "    chars_list = pickle.load(f)\n",
        "print(chars_list)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\t', '\\n', '、', '。', '々', 'ぁ', 'あ', 'ぃ', 'い', 'ぅ', 'う', 'ぇ', 'え', 'ぉ', 'お', 'か', 'が', 'き', 'ぎ', 'く', 'ぐ', 'け', 'げ', 'こ', 'ご', 'さ', 'ざ', 'し', 'じ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ', 'た', 'だ', 'ち', 'ぢ', 'っ', 'つ', 'づ', 'て', 'で', 'と', 'ど', 'な', 'に', 'ぬ', 'ね', 'の', 'は', 'ば', 'ぱ', 'ひ', 'び', 'ぴ', 'ふ', 'ぶ', 'ぷ', 'へ', 'べ', 'ぺ', 'ほ', 'ぼ', 'ぽ', 'ま', 'み', 'む', 'め', 'も', 'ゃ', 'や', 'ゅ', 'ゆ', 'ょ', 'よ', 'ら', 'り', 'る', 'れ', 'ろ', 'ゎ', 'わ', 'ゐ', 'ゑ', 'を', 'ん', 'ァ', 'ア', 'ィ', 'イ', 'ゥ', 'ウ', 'ェ', 'エ', 'ォ', 'オ', 'カ', 'ガ', 'キ', 'ギ', 'ク', 'グ', 'ケ', 'ゲ', 'コ', 'ゴ', 'サ', 'ザ', 'シ', 'ジ', 'ス', 'ズ', 'セ', 'ゼ', 'ソ', 'ゾ', 'タ', 'ダ', 'チ', 'ヂ', 'ッ', 'ツ', 'ヅ', 'テ', 'デ', 'ト', 'ド', 'ナ', 'ニ', 'ヌ', 'ネ', 'ノ', 'ハ', 'バ', 'パ', 'ヒ', 'ビ', 'ピ', 'フ', 'ブ', 'プ', 'ヘ', 'ベ', 'ペ', 'ホ', 'ボ', 'ポ', 'マ', 'ミ', 'ム', 'メ', 'モ', 'ャ', 'ヤ', 'ュ', 'ユ', 'ョ', 'ヨ', 'ラ', 'リ', 'ル', 'レ', 'ロ', 'ヮ', 'ワ', 'ヰ', 'ヱ', 'ヲ', 'ン', 'ヴ', '・', 'ー', '？']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRExeiQvHOSX"
      },
      "source": [
        "## 文章のベクトル化\n",
        "文章をone-hot表現に変換する関数を設定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7Dj7NVXHOSX"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# インデックスと文字で辞書を作成\n",
        "char_indices = {}\n",
        "for i, char in enumerate(chars_list):\n",
        "    char_indices[char] = i\n",
        "indices_char = {}\n",
        "for i, char in enumerate(chars_list):\n",
        "    indices_char[i] = char\n",
        "    \n",
        "n_char = len(chars_list)\n",
        "max_length_x = 128\n",
        "\n",
        "# 文章をone-hot表現に変換する関数\n",
        "def sentence_to_vector(sentence):\n",
        "    vector = np.zeros((1, max_length_x, n_char), dtype=np.bool)\n",
        "    for j, char in enumerate(sentence):\n",
        "        vector[0][j][char_indices[char]] = 1\n",
        "    return vector"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqDCAvwYHOSZ"
      },
      "source": [
        "## 返答作成用の関数\n",
        "encoderのモデル、およびdecoderのモデルを読み込み、返答を作成するための関数を設定します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsbgQ9mvHOSZ",
        "outputId": "618e2ddf-5161-41a1-99cc-b9dd511847cb"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "encoder_model = load_model('encoder_model.h5')\n",
        "decoder_model = load_model('decoder_model.h5')\n",
        "\n",
        "def respond(input_data, beta=5):\n",
        "    state_value = encoder_model.predict(input_data)\n",
        "    y_decoder = np.zeros((1, 1, n_char))  # decoderの出力を格納する配列\n",
        "    y_decoder[0][0][char_indices['\\t']] = 1  # decoderの最初の入力はタブ。one-hot表現にする。\n",
        "\n",
        "    respond_sentence = \"\"  # 返答の文字列\n",
        "    while True:\n",
        "        y, h = decoder_model.predict([y_decoder, state_value])\n",
        "        p_power = y[0][0] ** beta  # 確率分布の調整\n",
        "        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power)) \n",
        "        next_char = indices_char[next_index]  # 次の文字\n",
        "        \n",
        "        if (next_char == \"\\n\" or len(respond_sentence) >= max_length_x):\n",
        "            break  # 次の文字が改行のとき、もしくは最大文字数を超えたときは終了\n",
        "            \n",
        "        respond_sentence += next_char\n",
        "        y_decoder = np.zeros((1, 1, n_char))  # 次の時刻の入力\n",
        "        y_decoder[0][0][next_index] = 1\n",
        "\n",
        "        state_value = h  # 次の時刻の状態\n",
        "\n",
        "    return respond_sentence"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nRJGfvjHOSb"
      },
      "source": [
        "## 対話生成の検証\n",
        "コーパスに無い文章を使って、対話生成の検証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY_qSw1mHOSc",
        "outputId": "11652f0d-8352-414e-dfd1-8563d0220a9a"
      },
      "source": [
        "sentences = [\"けんじさん、こんにちは。\",\n",
        "             \"カムパネラってしってますか？\",\n",
        "             \"ああ、おなかすいた。\",\n",
        "             \"きょうはいいてんきですね。\",\n",
        "             \"すきなたべものは、なんですか。\",\n",
        "             \"きょうは、さんぽにいきました。\",\n",
        "             \"パソコンかスマホは、つかったことありますか？\"]\n",
        "\n",
        "for sentence in sentences:\n",
        "    vector = sentence_to_vector(sentence)\n",
        "    print(\"Input:\", sentence)\n",
        "    print(\"Response\", respond(vector))\n",
        "    print()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: けんじさん、こんにちは。\n",
            "Response せいねんはおまえたちのまえにいいました。\n",
            "\n",
            "Input: カムパネラってしってますか？\n",
            "Response ジョバンニはまっあかになっていました。\n",
            "\n",
            "Input: ああ、おなかすいた。\n",
            "Response たまはそうだ。\n",
            "\n",
            "Input: きょうはいいてんきですね。\n",
            "Response それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それか\n",
            "\n",
            "Input: すきなたべものは、なんですか。\n",
            "Response といいました。\n",
            "\n",
            "Input: きょうは、さんぽにいきました。\n",
            "Response それから、こんにちは、ああ、こんどはまたさぶろうのおとうさんがきょうしつのなかへとびだしました。\n",
            "\n",
            "Input: パソコンかスマホは、つかったことありますか？\n",
            "Response そうか。\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNu_co4DHOSd"
      },
      "source": [
        "完璧な回答になっているわけではありませんが、こちらの想像力が刺激されるような返答ですね。  \n",
        "人間が”会話をしている”と感じるためには、必ずしも正確な返答は必要ないのかもしれません。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wI5LW3GHOSe"
      },
      "source": [
        "## モデル同士の会話\n",
        "試しに、同じモデル同士に会話をさせてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqJt_ogcHOSe"
      },
      "source": [
        "response_a = \"こんにちは。\"\n",
        "response_b = \"\"\n",
        "for i in range(100):\n",
        "    print(\"賢治A:\", response_a)\n",
        "    print()  \n",
        "    vector_a = sentence_to_vector(response_a)\n",
        "    \n",
        "    response_b = respond(vector_a)\n",
        "    print(\"賢治B:\", response_b)\n",
        "    print()\n",
        "    vector_b = sentence_to_vector(response_b)\n",
        "    \n",
        "    response_a = respond(vector_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUSn5F-SHOSf"
      },
      "source": [
        "同じモデルを使ったためか、返答が似たような文章になる傾向がありますね。  \n",
        "今回は全く同じモデルを使いましたが、例えば乱歩の文章で訓練したモデルと、賢治のモデルで会話をさせても面白いかもしれません。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOHoniumHOSg"
      },
      "source": [
        "## さらに自然な会話のために\n",
        "さらに自然な会話ができるモデルを作るためには、例えば以下のようなアプローチが有効かもしれません。\n",
        "\n",
        "* **入力を単語ベクトルにする**  \n",
        "入力をone-hot表現ではなくword2vecなどにより作った単語ベクトルにします。  \n",
        "これにより、入力の次元数が抑えられるだけではなく、単語同士の関係性がSeq2Seqモデルの訓練前にすでに存在することになります。  \n",
        "しかしながら、返答を作成する際に、未知の単語を含む文章の入力に対応するのが難しくなります。  \n",
        "\n",
        "* **コーパスをさらに大きくする**  \n",
        "一般的に、コーパスが大きいほどモデルの汎用性は高まります。  \n",
        "しかしながら、学習に時間がかかるのでGPUの利用が必要になるかもしれません。\n",
        "\n",
        "* **コーパスは対話文のみとする**  \n",
        "今回は宮沢賢治の小説をコーパスにしましたので、対話文以外も多く含んでいます。  \n",
        "しかしながら、用途を対話のみに絞るのであれば対話文のみを用意した方が精度が上がります。  \n",
        "大量の対話文を用意するのは大変ですが、SNS上でのやりとりなどをコーパスとして使うのも一つの手かもしれません。\n",
        "\n",
        "* **最新のアルゴリズムを採用する**  \n",
        "自然言語処理の分野では日々新しい技術が生まれ、論文などで発表されています。  \n",
        "興味のある方は、そのような技術をモデルに取り入れてみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrZV0athHOSh"
      },
      "source": [
        "## 課題\n",
        "betaの値を少し変更して、モデル同士に会話をさせてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndd5Q2c3HOSi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}